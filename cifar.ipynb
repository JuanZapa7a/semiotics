{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLGkt5qiyz4E"
      },
      "source": [
        "# Introduction to BNNs with Larq\n",
        "\n",
        "This tutorial demonstrates how to train a simple binarized Convolutional Neural Network (CNN) to classify MNIST digits. This simple network will achieve approximately 98% accuracy on the MNIST test set. This tutorial uses Larq and the [Keras Sequential API](https://www.tensorflow.org/guide/keras), so creating and training our model will require only a few lines of code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# import larq as lq\n",
        "\n",
        "!pip -q install tensorflow==2.10.0\n",
        "!pip -q install larq==0.13.1\n",
        "\n",
        "import tensorflow as tf\n",
        "import larq as lq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "### Download and prepare the CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWoEqyMuXFF4"
      },
      "outputs": [],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "#train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "#test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# Normalize pixel values to be between -1 and 1\n",
        "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1\n",
        "\n",
        "print(train_images.shape, train_labels.shape)  # Debe ser (50000, 32, 32, 3), (50000, 1)\n",
        "print(test_images.shape, test_labels.shape)    # Debe ser (10000, 32, 32, 3), (10000, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oewp-wYg31t9"
      },
      "source": [
        "### Create the model\n",
        "\n",
        "The following will create a simple binarized CNN.\n",
        "\n",
        "The quantization function\n",
        "$$\n",
        "q(x) = \\begin{cases}\n",
        "    -1 & x < 0 \\\\\\\n",
        "    1 & x \\geq 0\n",
        "\\end{cases}\n",
        "$$\n",
        "is used in the forward pass to binarize the activations and the latent full precision weights. The gradient of this function is zero almost everywhere which prevents the model from learning.\n",
        "\n",
        "To be able to train the model the gradient is instead estimated using the Straight-Through Estimator (STE)\n",
        "(the binarization is essentially replaced by a clipped identity on the backward pass):\n",
        "$$\n",
        "\\frac{\\partial q(x)}{\\partial x} = \\begin{cases}\n",
        "    1 & \\left|x\\right| \\leq 1 \\\\\\\n",
        "    0 & \\left|x\\right| > 1\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "In Larq this can be done by using `input_quantizer=\"ste_sign\"` and `kernel_quantizer=\"ste_sign\"`.\n",
        "Additionally, the latent full precision weights are clipped to -1 and 1 using `kernel_constraint=\"weight_clip\"`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9YmGQBQPrdn"
      },
      "outputs": [],
      "source": [
        "# All quantized layers except the first will use the same options\n",
        "kwargs = dict(input_quantizer=\"ste_sign\",\n",
        "              kernel_quantizer=\"ste_sign\",\n",
        "              kernel_constraint=\"weight_clip\")\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# In the first layer we only quantize the weights and not the input\n",
        "# Change the input_shape to (32, 32, 3) to match the training data\n",
        "model.add(lq.layers.QuantConv2D(32, (3, 3),\n",
        "                                kernel_quantizer=\"ste_sign\",\n",
        "                                kernel_constraint=\"weight_clip\",\n",
        "                                use_bias=False,\n",
        "                                input_shape=(32, 32, 3)))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "model.add(lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "model.add(lq.layers.QuantDense(64, use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(lq.layers.QuantDense(10, use_bias=False, **kwargs))\n",
        "model.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model.add(tf.keras.layers.Activation(\"softmax\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvDVFkg-2DPm"
      },
      "source": [
        "Almost all parameters in the network are binarized, so either -1 or 1. This makes the network extremely fast if it would be deployed on custom BNN hardware.\n",
        "\n",
        " Here is the complete architecture of our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-C4XBg4UTJy"
      },
      "outputs": [],
      "source": [
        "lq.models.summary(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_2 = tf.keras.models.Sequential()\n",
        "\n",
        "# En la primera capa convolucional, configuramos el input_shape según el tamaño de los datos de entrada\n",
        "model_2.add(tf.keras.layers.Conv2D(32, (3, 3), use_bias=False, input_shape=(32, 32, 3)))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_2.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Segunda capa convolucional\n",
        "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), use_bias=False))\n",
        "model_2.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_2.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Tercera capa convolucional\n",
        "model_2.add(tf.keras.layers.Conv2D(64, (3, 3), use_bias=False))\n",
        "model_2.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Aplanado para pasar a capas densas\n",
        "model_2.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Primera capa densa\n",
        "model_2.add(tf.keras.layers.Dense(64, use_bias=False))\n",
        "model_2.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Segunda capa densa\n",
        "model_2.add(tf.keras.layers.Dense(10, use_bias=False))\n",
        "model_2.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Activación final con softmax para clasificación de 10 clases\n",
        "model_2.add(tf.keras.layers.Activation(\"softmax\"))\n",
        "\n",
        "# Obtener el resumen del modelo\n",
        "model_2.summary()\n"
      ],
      "metadata": {
        "id": "ga9k4LZTiq2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Después de definir el modelo\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "XIi-no2PiwJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3odqfHP4M67"
      },
      "source": [
        "### Compile and train the model\n",
        "\n",
        "Note: This may take a few minutes depending on your system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MdDzI75PUXrG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(train_images, train_labels, batch_size=64, epochs=6, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKgyC5K_4O0d"
      },
      "source": [
        "### Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LvwaKhtUdOo"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Graficar las curvas de precisión y pérdida\n",
        "# Asegúrate de que `val_images` y `val_labels` estén definidos si quieres usar datos de validación\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear la figura\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Graficar la precisión de entrenamiento\n",
        "if 'accuracy' in history.history:\n",
        "    plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')\n",
        "\n",
        "# Graficar la precisión de validación, si está disponible\n",
        "if 'val_accuracy' in history.history:\n",
        "    plt.plot(history.history['val_accuracy'], label='Precisión de validación')\n",
        "\n",
        "# Graficar la pérdida de entrenamiento\n",
        "if 'loss' in history.history:\n",
        "    plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "\n",
        "# Graficar la pérdida de validación, si está disponible\n",
        "if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "\n",
        "# Etiquetas y leyenda\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Curvas de Entrenamiento y Validación')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9C-_Hkumu6kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cfJ8AR03gT5"
      },
      "source": [
        "As you can see, our simple binarized CNN has achieved a test accuracy of around 98 %. Not bad for a few lines of code!\n",
        "\n",
        "For information on converting Larq models to an optimized format and using or benchmarking them on Android or ARM devices, have a look at [this guide](https://docs.larq.dev/compute-engine/end_to_end/)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history_2 = model_2.fit(train_images, train_labels, batch_size=64, epochs=6, validation_split=0.2)\n"
      ],
      "metadata": {
        "id": "uymMQFfokIrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_2.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy {test_acc * 100:.2f} %\")"
      ],
      "metadata": {
        "id": "E4WNZZVUkNoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Graficar las curvas de precisión y pérdida\n",
        "# Asegúrate de que `val_images` y `val_labels` estén definidos si quieres usar datos de validación\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Crear la figura\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Graficar la precisión de entrenamiento\n",
        "if 'accuracy' in history_2.history:\n",
        "    plt.plot(history_2.history['accuracy'], label='Precisión de entrenamiento')\n",
        "\n",
        "# Graficar la precisión de validación, si está disponible\n",
        "if 'val_accuracy' in history_2.history:\n",
        "    plt.plot(history_2.history['val_accuracy'], label='Precisión de validación')\n",
        "\n",
        "# Graficar la pérdida de entrenamiento\n",
        "if 'loss' in history_2.history:\n",
        "    plt.plot(history_2.history['loss'], label='Pérdida de entrenamiento')\n",
        "\n",
        "# Graficar la pérdida de validación, si está disponible\n",
        "if 'val_loss' in history_2.history:\n",
        "    plt.plot(history_2.history['val_loss'], label='Pérdida de validación')\n",
        "\n",
        "# Etiquetas y leyenda\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Valor')\n",
        "plt.title('Curvas de Entrenamiento y Validación')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Iq1tY0KmsRMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "intro_to_cnns.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}