{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/semiotics/blob/main/QAT_MNIST_NOISY_CMOS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvasZKNzJ-WT"
      },
      "source": [
        "# Quantization Aware Training (QAT) using Larq for a noisy CMOS binarized quantization with the CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op030X-yW5Pv"
      },
      "source": [
        "## 1. Installation of Larq and necessary dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAve6DCL4JH4"
      },
      "outputs": [],
      "source": [
        "!pip -q install tensorflow==2.10.0\n",
        "!pip -q install larq==0.13.1\n",
        "\n",
        "import tensorflow as tf\n",
        "import larq as lq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRFxccghyMVo"
      },
      "source": [
        "## 2. Data preparation (MNIST)\n",
        "\n",
        "Download and prepare the MNIST dataset.\n",
        "\n",
        "By default, each MNIST image has a shape of (28, 28), which is 2D.\n",
        "However, neural networks (especially convolutional networks) typically expect 3D inputs: (height, width, channels).\n",
        "Adding a channel dimension (with value 1 for grayscale) changes each image shape from (28, 28) to (28, 28, 1), which is required for most neural network layers to interpret the images correctly.\n",
        "The overall shapes for the dataset become (60000, 28, 28, 1) for training and (10000, 28, 28, 1) for testing.\n",
        "\n",
        "The MNIST dataset’s pixel values originally range from 0 to 255.\n",
        "Dividing by 127.5 and then subtracting 1 maps the values to a -1 to 1 range, which can help certain models converge more quickly and maintain numerical stability. (Centering pixel values around zero often benefits neural networks as it reduces bias and helps gradient-based methods perform better.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWoEqyMuXFF4",
        "outputId": "58fc1cf7-8628-4736-dfbc-e19d934cca3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "(60000, 28, 28, 1) (60000,)\n",
            "(10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)) # (60000, 28, 28) (60000,)\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)) # (10000, 28, 28) (10000,)\n",
        "\n",
        "# For binarized models, it is standard to normalize images to a range between -1 and 1.\n",
        "train_images, test_images = train_images / 127.5 - 1,test_images / 127.5 - 1\n",
        "\n",
        "print(train_images.shape, train_labels.shape)  # Debe ser (60000, 28, 28, 1), (60000,)\n",
        "print(test_images.shape, test_labels.shape)    # Debe ser (10000, 28, 28, 1), (10000,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxSwWsw0J-WV"
      },
      "source": [
        "## 3. AÑADIENDO RUIDO A LOS PESOS Y A LAS ACTIVACIONES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcfFb0N8fOrh"
      },
      "source": [
        "Para modificar el código y permitir que el ruido se inyecte tanto en los pesos como en las activaciones, podemos expandir la lógica de la clase `NoisyLayer`. Además, sí, las imágenes de entrada podrían venir con ruido (simulando ruido real del sensor o del ambiente), lo que podría mejorarse añadiendo ruido a las activaciones de cada capa.\n",
        "\n",
        "### **Código modificado para añadir ruido  a los pesos y activaciones:**\n",
        "\n",
        "1. **Inyectar ruido en las activaciones**:\n",
        "    - Modifica la función `call` de `NoisyLayer` para agregar ruido a las activaciones después de aplicar la lógica de la capa base.\n",
        "2. **Simular ruido en la entrada (opcional)**:\n",
        "    - Añade una capa adicional de ruido a las imágenes de entrada con `tf.keras.layers.GaussianNoise`.\n",
        "\n",
        "### **Explicación de los cambios**\n",
        "\n",
        "#### 1. **Ruido en activaciones**\n",
        "\n",
        "- Después de aplicar la lógica de la capa base (`self.wrapped_layer(inputs)`), se genera ruido para las activaciones con:\n",
        "    \n",
        "    ```python\n",
        "    activation_noise = tf.random.normal(\n",
        "        shape=tf.shape(outputs),\n",
        "        mean=self.noise_mean,\n",
        "        stddev=self.noise_stddev_activations\n",
        "    )\n",
        "    outputs_noisy = outputs + activation_noise\n",
        "    ```\n",
        "    \n",
        "- Esto inyecta ruido gaussiano en las salidas de cada capa.\n",
        "\n",
        "#### 2. **Simulación de imágenes de entrada con ruido**\n",
        "\n",
        "- La capa `tf.keras.layers.GaussianNoise` añade ruido gaussiano directamente a las imágenes de entrada:\n",
        "    \n",
        "    ```python\n",
        "    model.add(tf.keras.layers.GaussianNoise(0.05, input_shape=(28, 28, 1)))\n",
        "    ```\n",
        "    \n",
        "- Esto simula el ruido que podría provenir de sensores o entornos del mundo real.\n",
        "\n",
        "#### 3. **Parámetros separados para ruido en pesos y activaciones**\n",
        "\n",
        "- `noise_stddev_weights`: Desviación estándar para el ruido en los pesos.\n",
        "- `noise_stddev_activations`: Desviación estándar para el ruido en las activaciones.\n",
        "\n",
        "---\n",
        "\n",
        "### **Escenarios del ruido en imágenes**\n",
        "\n",
        "La simulación de ruido en las imágenes puede ser útil para:\n",
        "\n",
        "1. **Robustez a entradas ruidosas**:\n",
        "    - Por ejemplo, cámaras con baja iluminación, sensores defectuosos, o datos transmitidos con ruido.\n",
        "2. **Regularización adicional**:\n",
        "    - Similar a `Dropout`, añade variabilidad a las entradas, evitando que el modelo dependa de patrones específicos.\n",
        "\n",
        "---\n",
        "\n",
        "### **Resultados esperados**\n",
        "\n",
        "Con este enfoque:\n",
        "\n",
        "- El modelo será más robusto a perturbaciones tanto en las entradas como en las representaciones internas (activaciones y pesos).\n",
        "- Se puede usar para estudiar cómo el ruido afecta al rendimiento en diferentes partes del pipeline de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktrrzmFyfheO",
        "outputId": "2339759e-4a93-4c60-98ef-0673fe0400ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <bound method QuantizedVariable.from_variable of <class 'larq.quantized_variable.QuantizedVariable'>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <gast.gast.Expr object at 0x7e219b562620>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <bound method QuantizedVariable.from_variable of <class 'larq.quantized_variable.QuantizedVariable'>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: <gast.gast.Expr object at 0x7e219b562620>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "+sequential stats-----------------------------------------------------------------+\n",
            "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory |\n",
            "|                              (bit)                        x 1       x 1    (kB) |\n",
            "+---------------------------------------------------------------------------------+\n",
            "| gaussian_noise                   -   (-1, 28, 28, 1)        0         0       0 |\n",
            "| noisy_layer                      -  (-1, 26, 26, 32)      288         0    0.04 |\n",
            "| max_pooling2d                    -  (-1, 13, 13, 32)        0         0       0 |\n",
            "| batch_normalization              -  (-1, 13, 13, 32)        0        64    0.25 |\n",
            "| noisy_layer_1                    -  (-1, 11, 11, 64)    18432         0    2.25 |\n",
            "| max_pooling2d_1                  -    (-1, 5, 5, 64)        0         0       0 |\n",
            "| batch_normalization_1            -    (-1, 5, 5, 64)        0       128    0.50 |\n",
            "| noisy_layer_2                    -    (-1, 3, 3, 64)    36864         0    4.50 |\n",
            "| batch_normalization_2            -    (-1, 3, 3, 64)        0       128    0.50 |\n",
            "| flatten                          -         (-1, 576)        0         0       0 |\n",
            "| noisy_layer_3                    -          (-1, 64)    36864         0    4.50 |\n",
            "| batch_normalization_3            -          (-1, 64)        0       128    0.50 |\n",
            "| noisy_layer_4                    -          (-1, 10)      640         0    0.08 |\n",
            "| batch_normalization_4            -          (-1, 10)        0        20    0.08 |\n",
            "| activation                       -          (-1, 10)        0         0       0 |\n",
            "+---------------------------------------------------------------------------------+\n",
            "| Total                                                   93088       468   13.19 |\n",
            "+---------------------------------------------------------------------------------+\n",
            "+sequential summary-------------------------+\n",
            "| Total params                   93.6 k     |\n",
            "| Trainable params               93.1 k     |\n",
            "| Non-trainable params           468        |\n",
            "| Model size                     13.19 KiB  |\n",
            "| Model size (8-bit FP weights)  11.82 KiB  |\n",
            "| Float-32 Equivalent            365.45 KiB |\n",
            "| Compression Ratio of Memory    0.04       |\n",
            "| Number of MACs                 0          |\n",
            "+-------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import larq as lq\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a custom layer to add noise to weights and activations\n",
        "class NoisyLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, wrapped_layer, noise_mean=0.0, noise_stddev_weights=0.01, noise_stddev_activations=0.01, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.wrapped_layer = wrapped_layer                 # Original layer to wrap\n",
        "        self.noise_mean = noise_mean                       # Mean of the noise\n",
        "        self.noise_stddev_weights = noise_stddev_weights   # Stddev of noise for weights\n",
        "        self.noise_stddev_activations = noise_stddev_activations  # Stddev of noise for activations\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Build the wrapped layer\n",
        "        self.wrapped_layer.build(input_shape)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Add noise to weights\n",
        "        for weight in self.wrapped_layer.trainable_weights:\n",
        "            noise = tf.random.normal(\n",
        "                shape=tf.shape(weight),\n",
        "                mean=self.noise_mean,\n",
        "                stddev=self.noise_stddev_weights\n",
        "            )\n",
        "            noisy_weight = weight + noise  # Add noise to weights\n",
        "            weight.assign(noisy_weight)   # Assign the noisy weights temporarily\n",
        "\n",
        "        # Forward pass through the wrapped layer\n",
        "        outputs = self.wrapped_layer(inputs)\n",
        "\n",
        "        # Add noise to activations\n",
        "        activation_noise = tf.random.normal(\n",
        "            shape=tf.shape(outputs),\n",
        "            mean=self.noise_mean,\n",
        "            stddev=self.noise_stddev_activations\n",
        "        )\n",
        "        outputs_noisy = outputs + activation_noise\n",
        "\n",
        "        return outputs_noisy\n",
        "\n",
        "# Define default quantization options for quantized layers\n",
        "kwargs = dict(\n",
        "    input_quantizer=\"ste_sign\",\n",
        "    kernel_quantizer=\"ste_sign\",\n",
        "    kernel_constraint=\"weight_clip\"\n",
        ")\n",
        "\n",
        "# Initialize a Sequential model\n",
        "model_wa = tf.keras.models.Sequential()\n",
        "\n",
        "# Add noise to input images (simulate noisy input images)\n",
        "model_wa.add(tf.keras.layers.GaussianNoise(0.05, input_shape=(28, 28, 1)))\n",
        "\n",
        "# First convolutional layer with noise on weights and activations\n",
        "model_wa.add(NoisyLayer(\n",
        "    lq.layers.QuantConv2D(\n",
        "        32, (3, 3),\n",
        "        kernel_quantizer=\"ste_sign\",\n",
        "        kernel_constraint=\"weight_clip\",\n",
        "        use_bias=False\n",
        "    ),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01\n",
        "))\n",
        "model_wa.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_wa.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Second convolutional layer with noise on weights and activations\n",
        "model_wa.add(NoisyLayer(\n",
        "    lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01\n",
        "))\n",
        "model_wa.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_wa.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Third convolutional layer with noise on weights and activations\n",
        "model_wa.add(NoisyLayer(\n",
        "    lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01\n",
        "))\n",
        "model_wa.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model_wa.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Dense layer with noise on weights and activations\n",
        "model_wa.add(NoisyLayer(\n",
        "    lq.layers.QuantDense(64, use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01\n",
        "))\n",
        "model_wa.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Output layer with noise on weights and activations\n",
        "model_wa.add(NoisyLayer(\n",
        "    lq.layers.QuantDense(10, use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01\n",
        "))\n",
        "model_wa.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model_wa.add(tf.keras.layers.Activation(\"softmax\"))\n",
        "\n",
        "# Especificar la forma de entrada (28, 28, 1) para imágenes MNIST\n",
        "model_wa.build((None, 28, 28, 1))\n",
        "\n",
        "# Summarize the model with Larq\n",
        "lq.models.summary(model_wa)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicación de la salida\n",
        "\n",
        "Esta salida proporciona un resumen detallado de las características del modelo secuencial con cuantización y las estadísticas asociadas. Aquí está una explicación paso a paso de cada sección:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Tabla de capas con estadísticas (`+sequential stats+`)**\n",
        "#### **Columnas principales:**\n",
        "- **Layer**: Nombre de la capa en el modelo.\n",
        "- **Input prec. (bit)**: Precisión de los datos de entrada (no especificada aquí porque varía).\n",
        "- **Outputs**: Dimensión de la salida de la capa.\n",
        "- **# 1-bit**: Número de pesos binarios (1-bit) en la capa.\n",
        "- **# 32-bit**: Número de parámetros de 32 bits (normalmente de Batch Normalization).\n",
        "- **Memory (kB)**: Memoria requerida para almacenar los parámetros de la capa.\n",
        "\n",
        "#### **Detalles por capa:**\n",
        "1. **`gaussian_noise`**:\n",
        "   - Agrega ruido gaussiano al input. No tiene parámetros ni memoria asignada (solo afecta durante el entrenamiento).\n",
        "\n",
        "2. **`noisy_layer`**:\n",
        "   - La primera capa convolucional cuantizada con 32 filtros de 3x3:\n",
        "     - **288 pesos binarios (1-bit)**, calculados como: $ 3 \\times 3 \\times 1 \\times 32 = 288 $.\n",
        "     - **0 parámetros de 32 bits** porque la capa no usa sesgo.\n",
        "     - Memoria: **0.04 kB** (288 bits = 36 bytes = 0.04 kB).\n",
        "\n",
        "3. **`max_pooling2d`**:\n",
        "   - Reduce la dimensión espacial de la salida sin usar parámetros.\n",
        "\n",
        "4. **`batch_normalization`**:\n",
        "   - Normaliza la salida del pooling:\n",
        "     - **64 parámetros de 32 bits** (2 por filtro: media y desviación estándar).\n",
        "     - Memoria: **0.25 kB**.\n",
        "\n",
        "5. **`noisy_layer_1`**:\n",
        "   - Segunda capa convolucional con 64 filtros de 3x3:\n",
        "     - **18432 pesos binarios (1-bit)**, calculados como: $ 3 \\times 3 \\times 32 \\times 64 = 18432 $.\n",
        "     - Memoria: **2.25 kB**.\n",
        "\n",
        "6. **`batch_normalization_1`**:\n",
        "   - Igual que el anterior, pero ahora con **128 parámetros de 32 bits** porque hay 64 filtros.\n",
        "\n",
        "7. **`noisy_layer_2`**:\n",
        "   - Tercera capa convolucional:\n",
        "     - **36864 pesos binarios (1-bit)**, calculados como: $ 3 \\times 3 \\times 64 \\times 64 = 36864 $.\n",
        "     - Memoria: **4.50 kB**.\n",
        "\n",
        "8. **`flatten`**:\n",
        "   - Aplana la salida para conectarla a capas densas. No tiene parámetros.\n",
        "\n",
        "9. **`noisy_layer_3`**:\n",
        "   - Capa densa con 64 unidades:\n",
        "     - **36864 pesos binarios (1-bit)**, calculados como: $ 576 \\times 64 = 36864 $.\n",
        "     - Memoria: **4.50 kB**.\n",
        "\n",
        "10. **`noisy_layer_4`**:\n",
        "    - Capa de salida densa con 10 unidades:\n",
        "      - **640 pesos binarios (1-bit)**, calculados como: $ 64 \\times 10 = 640 $.\n",
        "      - Memoria: **0.08 kB**.\n",
        "\n",
        "11. **`activation`**:\n",
        "    - Usa una función `softmax`. No tiene parámetros.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Resumen general (`+sequential summary+`)**\n",
        "#### **Estadísticas importantes:**\n",
        "- **Total params**: Número total de parámetros:\n",
        "  - **93.6 k**: Representa 93088 pesos binarios (1-bit) y 468 parámetros de 32 bits.\n",
        "\n",
        "- **Trainable params**: Parámetros ajustables durante el entrenamiento:\n",
        "  - **93.1 k**, que incluye los pesos binarios (1-bit) y parámetros de Batch Normalization.\n",
        "\n",
        "- **Non-trainable params**: Parámetros que no se ajustan (e.g., estadísticas acumuladas en Batch Normalization):\n",
        "  - **468**.\n",
        "\n",
        "- **Model size**:\n",
        "  - **13.19 KiB**: Tamaño total del modelo en memoria comprimida (pesos binarios).\n",
        "  - **Model size (8-bit FP weights)**: Si se almacenaran en precisión de 8 bits, ocuparían **11.82 KiB**.\n",
        "  - **Float-32 Equivalent**: Si todos los pesos fueran flotantes de 32 bits, el modelo ocuparía **365.45 KiB**.\n",
        "\n",
        "- **Compression Ratio of Memory**:\n",
        "  - **0.04**: Indica que el modelo es 25 veces más pequeño (4%) en comparación con su equivalente en punto flotante de 32 bits.\n",
        "\n",
        "- **Number of MACs**:\n",
        "  - **0**: Esto puede deberse a que el modelo usa operaciones de conteo de bits (binarias) en lugar de acumulaciones/multiplicaciones tradicionales (MAC).\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusión**\n",
        "La salida refleja que este modelo es **altamente eficiente en términos de memoria**, gracias al uso de **cuantización binaria** para los pesos. Aunque esto reduce la precisión de los cálculos, el modelo sigue siendo compacto y adecuado para dispositivos con recursos limitados, como hardware IoT o ASICs personalizados.\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Tabla de capas con estadísticas (`+sequential stats+`)**\n",
        "#### **Columnas principales:**\n",
        "- **Layer**: Nombre de la capa en el modelo.\n",
        "- **Input prec. (bit)**: Precisión de los datos de entrada (no especificada aquí porque varía).\n",
        "- **Outputs**: Dimensión de la salida de la capa.\n",
        "- **# 1-bit**: Número de pesos binarios (1-bit) en la capa.\n",
        "- **# 32-bit**: Número de parámetros de 32 bits (normalmente de Batch Normalization).\n",
        "- **Memory (kB)**: Memoria requerida para almacenar los parámetros de la capa.\n",
        "\n",
        "#### **Detalles por capa:**\n",
        "1. **`gaussian_noise`**:\n",
        "   - Agrega ruido gaussiano al input. No tiene parámetros ni memoria asignada (solo afecta durante el entrenamiento).\n",
        "\n",
        "2. **`noisy_layer`**:\n",
        "   - La primera capa convolucional cuantizada con 32 filtros de 3x3:\n",
        "     - **288 pesos binarios (1-bit)**, calculados como: $ 3 \\times 3 \\times 1 \\times 32 = 288 $.\n",
        "     - **0 parámetros de 32 bits** porque la capa no usa sesgo.\n",
        "     - Memoria: **0.04 kB** (288 bits = 36 bytes = 0.04 kB).\n",
        "\n",
        "3. **`max_pooling2d`**:\n",
        "   - Reduce la dimensión espacial de la salida sin usar parámetros.\n",
        "\n",
        "4. **`batch_normalization`**:\n",
        "   - Normaliza la salida del pooling:\n",
        "     - **64 parámetros de 32 bits** (2 por filtro: media y desviación estándar).\n",
        "     - Memoria: **0.25 kB**.\n",
        "\n",
        "5. **`noisy_layer_1`**:\n",
        "   - Segunda capa convolucional con 64 filtros de 3x3:\n",
        "     - **18432 pesos binarios (1-bit)**, calculados como: $ 3 \\times 3 \\times 32 \\times 64 = 18432 $.\n",
        "     - Memoria: **2.25 kB**.\n",
        "\n",
        "6. **`batch_normalization_1`**:\n",
        "   - Igual que el anterior, pero ahora con **128 parámetros de 32 bits** porque hay 64 filtros.\n",
        "\n",
        "7. **`noisy_layer_2`**:\n",
        "   - Tercera capa convolucional:\n",
        "     - **36864 pesos binarios (1-bit)**, calculados como: $ 3 \\times 3 \\times 64 \\times 64 = 36864 $.\n",
        "     - Memoria: **4.50 kB**.\n",
        "\n",
        "8. **`flatten`**:\n",
        "   - Aplana la salida para conectarla a capas densas. No tiene parámetros.\n",
        "\n",
        "9. **`noisy_layer_3`**:\n",
        "   - Capa densa con 64 unidades:\n",
        "     - **36864 pesos binarios (1-bit)**, calculados como: $ 576 \\times 64 = 36864 $.\n",
        "     - Memoria: **4.50 kB**.\n",
        "\n",
        "10. **`noisy_layer_4`**:\n",
        "    - Capa de salida densa con 10 unidades:\n",
        "      - **640 pesos binarios (1-bit)**, calculados como: $ 64 \\times 10 = 640 $.\n",
        "      - Memoria: **0.08 kB**.\n",
        "\n",
        "11. **`activation`**:\n",
        "    - Usa una función `softmax`. No tiene parámetros.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Resumen general (`+sequential summary-------------------------+`)**\n",
        "#### **Estadísticas importantes:**\n",
        "- **Total params**: Número total de parámetros:\n",
        "  - **93.6 k**: Representa 93088 pesos binarios (1-bit) y 468 parámetros de 32 bits.\n",
        "\n",
        "- **Trainable params**: Parámetros ajustables durante el entrenamiento:\n",
        "  - **93.1 k**, que incluye los pesos binarios (1-bit) y parámetros de Batch Normalization.\n",
        "\n",
        "- **Non-trainable params**: Parámetros que no se ajustan (e.g., estadísticas acumuladas en Batch Normalization):\n",
        "  - **468**.\n",
        "\n",
        "- **Model size**:\n",
        "  - **13.19 KiB**: Tamaño total del modelo en memoria comprimida (pesos binarios).\n",
        "  - **Model size (8-bit FP weights)**: Si se almacenaran en precisión de 8 bits, ocuparían **11.82 KiB**.\n",
        "  - **Float-32 Equivalent**: Si todos los pesos fueran flotantes de 32 bits, el modelo ocuparía **365.45 KiB**.\n",
        "\n",
        "- **Compression Ratio of Memory**:\n",
        "  - **0.04**: Indica que el modelo es 25 veces más pequeño (4%) en comparación con su equivalente en punto flotante de 32 bits.\n",
        "\n",
        "- **Number of MACs**:\n",
        "  - **0**: Esto puede deberse a que el modelo usa operaciones de conteo de bits (binarias) en lugar de acumulaciones/multiplicaciones tradicionales (MAC).\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusión**\n",
        "La salida refleja que este modelo es **altamente eficiente en términos de memoria**, gracias al uso de **cuantización binaria** para los pesos. Aunque esto reduce la precisión de los cálculos, el modelo sigue siendo compacto y adecuado para dispositivos con recursos limitados, como hardware IoT o ASICs personalizados.\n",
        "\n",
        "El número de operaciones MAC (multiplicación-acumulación) aparece como **0** porque el modelo usa **cuantización binaria** para los pesos y, posiblemente, para las activaciones. Esto elimina las operaciones tradicionales de multiplicación y acumulación en favor de operaciones mucho más simples, como **suma de conteos de bits** o **XOR**. Veamos por qué y cuál es el impacto de esto:\n",
        "\n",
        "---\n",
        "\n",
        "### **1. Por qué el número de MACs es 0**\n",
        "En modelos binarizados:\n",
        "- Los pesos son representados en **1-bit**.\n",
        "- Las multiplicaciones de precisión completa entre activaciones y pesos se reemplazan por:\n",
        "  - Operaciones binarias, como XOR, para simular multiplicaciones.\n",
        "  - Sumas de bits resultantes para reemplazar acumulaciones.\n",
        "\n",
        "Dado que estas operaciones no son multiplicaciones reales en punto flotante o fijo (y Larq optimiza el modelo para hardware binario), no se cuentan como MACs tradicionales.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. ¿Tiene sentido modelar las variaciones del proceso CMOS aquí?**\n",
        "Sí, sigue teniendo sentido añadir las **variaciones del proceso CMOS**, incluso si el modelo no realiza operaciones MAC tradicionales. Esto se debe a que las variaciones del proceso CMOS **pueden influir en el comportamiento de las operaciones binarias y la estabilidad general del hardware**. Aquí hay algunas razones:\n",
        "\n",
        "#### **Efecto de variaciones CMOS en operaciones binarias:**\n",
        "1. **Errores en las operaciones XOR/SUMA:**\n",
        "   - Las variaciones de umbral de voltaje (Vt) pueden afectar la precisión de las operaciones XOR o sumas binarias, introduciendo errores aleatorios.\n",
        "\n",
        "2. **Ruido en activaciones y pesos binarizados:**\n",
        "   - Aunque las multiplicaciones completas se eliminan, las activaciones binarizadas y los pesos pueden estar sujetos a variaciones inducidas por CMOS. Esto podría desbalancear los resultados del conteo de bits.\n",
        "\n",
        "3. **Hardware realista:**\n",
        "   - Cuando el modelo se implementa en hardware como ASICs o FPGAs, estas variaciones afectan los cálculos a nivel físico, incluso si no hay operaciones MAC tradicionales.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Cómo justificar la inclusión de variaciones CMOS**\n",
        "Añadir variaciones del proceso CMOS puede ser útil para:\n",
        "- **Simular hardware realista:** Asegurarte de que el modelo funcione bien en hardware con restricciones prácticas y variaciones físicas.\n",
        "- **Aumentar la robustez:** Introducir ruido durante el entrenamiento puede hacer que el modelo sea más tolerante a los errores inducidos por hardware.\n",
        "- **Analizar degradación del rendimiento:** Permitir estudiar cómo las variaciones afectan la precisión general del modelo.\n",
        "\n",
        "---\n",
        "\n",
        "### **Conclusión**\n",
        "Aunque las operaciones MAC no aparecen en modelos binarizados, las variaciones del proceso CMOS afectan otros aspectos del hardware, como las operaciones XOR y el conteo de bits. Por tanto, **sí tiene sentido incluir estas variaciones** para hacer el modelo más robusto y representativo del comportamiento en hardware real. Esto es particularmente relevante si planeas implementarlo en sistemas integrados que usan tecnología CMOS."
      ],
      "metadata": {
        "id": "MMUTZxwrOUTD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdDzI75PUXrG",
        "outputId": "57c7fdd5-44db-435e-abfe-2afdf937435b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "938/938 [==============================] - 118s 123ms/step - loss: 1.0993 - accuracy: 0.7421 - val_loss: 1.2276 - val_accuracy: 0.7237\n",
            "Epoch 2/6\n",
            "938/938 [==============================] - 105s 112ms/step - loss: 0.8363 - accuracy: 0.8550 - val_loss: 1.0061 - val_accuracy: 0.8196\n",
            "Epoch 3/6\n",
            "938/938 [==============================] - 105s 112ms/step - loss: 0.7155 - accuracy: 0.8958 - val_loss: 0.7922 - val_accuracy: 0.8881\n",
            "Epoch 4/6\n",
            "938/938 [==============================] - 102s 108ms/step - loss: 0.6504 - accuracy: 0.9136 - val_loss: 0.7438 - val_accuracy: 0.9122\n",
            "Epoch 5/6\n",
            "938/938 [==============================] - 105s 112ms/step - loss: 0.6154 - accuracy: 0.9258 - val_loss: 0.6766 - val_accuracy: 0.9259\n",
            "Epoch 6/6\n",
            "938/938 [==============================] - 103s 109ms/step - loss: 0.5830 - accuracy: 0.9348 - val_loss: 0.6497 - val_accuracy: 0.9333\n",
            "313/313 [==============================] - 9s 28ms/step - loss: 0.7649 - accuracy: 0.9168\n",
            "Test Accuracy: 91.68%\n",
            "Test Loss: 0.7649\n"
          ]
        }
      ],
      "source": [
        "# Compile the model with an optimizer and loss function\n",
        "model_wa.compile(\n",
        "    optimizer='adam',                      # Adam optimizer is often effective for training binarized networks\n",
        "    loss=\"sparse_categorical_crossentropy\",# Cross-entropy loss for classification\n",
        "    metrics=[\"accuracy\"]                   # Accuracy as the evaluation metric\n",
        ")\n",
        "\n",
        "# Train the model where QAT takes place as the model learns to optimize quantized weights and activations.\n",
        "history_wa = model_wa.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=6,                           # Number of training epochs\n",
        "    batch_size=64,                      # Batch size for training\n",
        "    validation_data=(test_images, test_labels), # Evaluate on test set after each epoch\n",
        "    shuffle=False                        # Shuffle the training data for each epoch\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model_wa.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_J3WWz5J-WW"
      },
      "source": [
        "## 4. VARIACIONES DE PROCESO CMOS\n",
        "\n",
        "Las variaciones de proceso pueden cambiar los parámetros de los transistores, afectando el comportamiento de las operaciones aritméticas. Esto puede modelarse como una desviación en los pesos del modelo.\n",
        "\n",
        "### **Análisis del Código Actual**\n",
        "\n",
        "hemos definido un modelo de red neuronal convolucional en **TensorFlow** con capas cuantizadas usando **Larq**. Además, hemos implementado una capa personalizada (`NoisyLayer`) que introduce ruido gaussiano en los pesos y activaciones de otras capas para simular imprecisiones o ruido en el hardware en un modelo CNN llamado `model_wa` (**noise in weights and activations**).\n",
        "\n",
        "#### **Características**\n",
        "1. **Capa personalizada (`NoisyLayer`)**:\n",
        "   - **Pesos**: Introduce ruido gaussiano en los pesos de la capa antes de la operación `call`.\n",
        "   - **Activaciones**: Añade ruido gaussiano a las salidas de la capa.\n",
        "\n",
        "2. **Modelo secuencial (`model_wa`)**:\n",
        "   - Se utiliza ruido en los datos de entrada/imagen (`GaussianNoise`).\n",
        "   - Cada capa convolucional y densa está envuelta (wrapped) con `NoisyLayer` para simular hardware ruidoso.\n",
        "   - Usamos Larq (`lq`) para implementar las capas cuantizadas para QAT.\n",
        "\n",
        "3. **Finalidad del diseño**: Simular entornos con hardware real. El modelo es lo suficiente robusto frente al ruido inducido.\n",
        "\n",
        "---\n",
        "\n",
        "### **Introducir Variaciones del Proceso CMOS**\n",
        "\n",
        "El comportamiento de un circuito CMOS puede ser afectado por **variaciones de proceso**, que incluyen:\n",
        "- **Threshold Voltage Variation (Vt)**: Cambios en el umbral de los transistores afectan operaciones lógicas y de cuantización.\n",
        "- **Capacitive Coupling Noise**: Introduce inexactitudes adicionales.\n",
        "- **Temperature-induced Drift**: Cambios estocásticos en la precisión debido a temperatura.\n",
        "\n",
        "Para modelar estas variaciones, podemos extender el comportamiento del `NoisyLayer` para incluir:\n",
        "1. **Imprecisiones en operaciones aritméticas específicas** (e.g., multiplicación, suma).\n",
        "2. **Sesgo adicional en el ruido de pesos y activaciones basado en drift térmico o variación de Vt**.\n",
        "\n",
        "\n",
        "### **Explicación de Modificaciones**\n",
        "1. **Variación de Voltaje de Umbral (Vt)**:\n",
        "   - Añadimos un término multiplicativo `1 + vt_variation` en los pesos para modelar el efecto de variaciones estocásticas del proceso CMOS.\n",
        "\n",
        "2. **Ruido por Acoplamiento Capacitivo**:\n",
        "   - Introducimos un ruido gaussiano adicional (`capacitive_noise_stddev`) en las activaciones para reflejar la interferencia de acoplamiento.\n",
        "\n",
        "3. **Nueva Clase (`CMOSNoisyLayer`)**:\n",
        "   - Esta capa personalizada es una extensión de `NoisyLayer` que incluye las variaciones mencionadas.\n",
        "\n",
        "---\n",
        "\n",
        "Este modelo pretende ser `más realista` para simulaciones en hardware CMOS, ya que incorpora características específicas del proceso de fabricación y las operaciones aritméticas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBl-wmm7J-WW",
        "outputId": "6c1ab065-4c63-4e16-967d-76070c2e2301"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+sequential stats-----------------------------------------------------------------+\n",
            "| Layer                  Input prec.           Outputs  # 1-bit  # 32-bit  Memory |\n",
            "|                              (bit)                        x 1       x 1    (kB) |\n",
            "+---------------------------------------------------------------------------------+\n",
            "| gaussian_noise                   -   (-1, 28, 28, 1)        0         0       0 |\n",
            "| noisy_layer                      -  (-1, 26, 26, 32)      288         0    0.04 |\n",
            "| max_pooling2d                    -  (-1, 13, 13, 32)        0         0       0 |\n",
            "| batch_normalization              -  (-1, 13, 13, 32)        0        64    0.25 |\n",
            "| noisy_layer_1                    -  (-1, 11, 11, 64)    18432         0    2.25 |\n",
            "| max_pooling2d_1                  -    (-1, 5, 5, 64)        0         0       0 |\n",
            "| batch_normalization_1            -    (-1, 5, 5, 64)        0       128    0.50 |\n",
            "| noisy_layer_2                    -    (-1, 3, 3, 64)    36864         0    4.50 |\n",
            "| batch_normalization_2            -    (-1, 3, 3, 64)        0       128    0.50 |\n",
            "| flatten                          -         (-1, 576)        0         0       0 |\n",
            "| noisy_layer_3                    -          (-1, 64)    36864         0    4.50 |\n",
            "| batch_normalization_3            -          (-1, 64)        0       128    0.50 |\n",
            "| noisy_layer_4                    -          (-1, 10)      640         0    0.08 |\n",
            "| batch_normalization_4            -          (-1, 10)        0        20    0.08 |\n",
            "| activation                       -          (-1, 10)        0         0       0 |\n",
            "+---------------------------------------------------------------------------------+\n",
            "| Total                                                   93088       468   13.19 |\n",
            "+---------------------------------------------------------------------------------+\n",
            "+sequential summary-------------------------+\n",
            "| Total params                   93.6 k     |\n",
            "| Trainable params               93.1 k     |\n",
            "| Non-trainable params           468        |\n",
            "| Model size                     13.19 KiB  |\n",
            "| Model size (8-bit FP weights)  11.82 KiB  |\n",
            "| Float-32 Equivalent            365.45 KiB |\n",
            "| Compression Ratio of Memory    0.04       |\n",
            "| Number of MACs                 0          |\n",
            "+-------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import larq as lq\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define a custom layer to add CMOS process variation effects\n",
        "class CMOSNoisyLayer(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        wrapped_layer,\n",
        "        noise_mean=0.0,\n",
        "        noise_stddev_weights=0.01,\n",
        "        noise_stddev_activations=0.01,\n",
        "        vt_variation_factor=0.001,\n",
        "        capacitive_noise_stddev=0.005,\n",
        "        **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.wrapped_layer = wrapped_layer                 # Original layer to wrap\n",
        "        self.noise_mean = noise_mean                       # Mean of the noise\n",
        "        self.noise_stddev_weights = noise_stddev_weights   # Stddev of noise for weights\n",
        "        self.noise_stddev_activations = noise_stddev_activations  # Stddev of noise for activations\n",
        "        self.vt_variation_factor = vt_variation_factor     # Threshold voltage variation factor\n",
        "        self.capacitive_noise_stddev = capacitive_noise_stddev  # Capacitive coupling noise\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.wrapped_layer.build(input_shape)\n",
        "        super().build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Add noise to weights (including CMOS process variations)\n",
        "        for weight in self.wrapped_layer.trainable_weights:\n",
        "            noise = tf.random.normal(\n",
        "                shape=tf.shape(weight),\n",
        "                mean=self.noise_mean,\n",
        "                stddev=self.noise_stddev_weights\n",
        "            )\n",
        "            vt_variation = tf.random.uniform(\n",
        "                shape=tf.shape(weight),\n",
        "                minval=-self.vt_variation_factor,\n",
        "                maxval=self.vt_variation_factor\n",
        "            )\n",
        "            noisy_weight = weight * (1 + vt_variation) + noise  # Combine variations\n",
        "            weight.assign(noisy_weight)  # Assign noisy weights temporarily\n",
        "\n",
        "        # Forward pass through the wrapped layer\n",
        "        outputs = self.wrapped_layer(inputs)\n",
        "\n",
        "        # Add noise to activations\n",
        "        activation_noise = tf.random.normal(\n",
        "            shape=tf.shape(outputs),\n",
        "            mean=self.noise_mean,\n",
        "            stddev=self.noise_stddev_activations\n",
        "        )\n",
        "        capacitive_noise = tf.random.normal(\n",
        "            shape=tf.shape(outputs),\n",
        "            mean=0.0,\n",
        "            stddev=self.capacitive_noise_stddev\n",
        "        )\n",
        "        outputs_noisy = outputs + activation_noise + capacitive_noise  # Add combined noise\n",
        "\n",
        "        return outputs_noisy\n",
        "\n",
        "\n",
        "# Define default quantization options for quantized layers\n",
        "kwargs = dict(\n",
        "    input_quantizer=\"ste_sign\",\n",
        "    kernel_quantizer=\"ste_sign\",\n",
        "    kernel_constraint=\"weight_clip\"\n",
        ")\n",
        "\n",
        "# Initialize a Sequential model\n",
        "model_wa_cmos = tf.keras.models.Sequential()\n",
        "\n",
        "# Add noise to input images (simulate noisy input images)\n",
        "model_wa_cmos.add(tf.keras.layers.GaussianNoise(0.05, input_shape=(28, 28, 1)))\n",
        "\n",
        "# First convolutional layer with CMOS process noise\n",
        "model_wa_cmos.add(CMOSNoisyLayer(\n",
        "    lq.layers.QuantConv2D(\n",
        "        32, (3, 3),\n",
        "        kernel_quantizer=\"ste_sign\",\n",
        "        kernel_constraint=\"weight_clip\",\n",
        "        use_bias=False\n",
        "    ),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01,\n",
        "    vt_variation_factor=0.002,\n",
        "    capacitive_noise_stddev=0.005\n",
        "))\n",
        "model_wa_cmos.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_wa_cmos.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Second convolutional layer\n",
        "model_wa_cmos.add(CMOSNoisyLayer(\n",
        "    lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01,\n",
        "    vt_variation_factor=0.002,\n",
        "    capacitive_noise_stddev=0.005\n",
        "))\n",
        "model_wa_cmos.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "model_wa_cmos.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Third convolutional layer\n",
        "model_wa_cmos.add(CMOSNoisyLayer(\n",
        "    lq.layers.QuantConv2D(64, (3, 3), use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01,\n",
        "    vt_variation_factor=0.002,\n",
        "    capacitive_noise_stddev=0.005\n",
        "))\n",
        "model_wa_cmos.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model_wa_cmos.add(tf.keras.layers.Flatten())\n",
        "\n",
        "# Dense layer\n",
        "model_wa_cmos.add(CMOSNoisyLayer(\n",
        "    lq.layers.QuantDense(64, use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01,\n",
        "    vt_variation_factor=0.002,\n",
        "    capacitive_noise_stddev=0.005\n",
        "))\n",
        "model_wa_cmos.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "\n",
        "# Output layer\n",
        "model_wa_cmos.add(CMOSNoisyLayer(\n",
        "    lq.layers.QuantDense(10, use_bias=False, **kwargs),\n",
        "    noise_stddev_weights=0.01,\n",
        "    noise_stddev_activations=0.01,\n",
        "    vt_variation_factor=0.002,\n",
        "    capacitive_noise_stddev=0.005\n",
        "))\n",
        "model_wa_cmos.add(tf.keras.layers.BatchNormalization(scale=False))\n",
        "model_wa_cmos.add(tf.keras.layers.Activation(\"softmax\"))\n",
        "\n",
        "# Especificar la forma de entrada (28, 28, 1) para imágenes MNIST\n",
        "model_wa_cmos.build((None, 28, 28, 1))\n",
        "\n",
        "# Summarize the model with Larq\n",
        "lq.models.summary(model_wa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BzZqVCEUJ-WW",
        "outputId": "1bab65b1-ac12-4a4f-f4b1-149dc7111981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "938/938 [==============================] - 141s 148ms/step - loss: 1.1081 - accuracy: 0.7367 - val_loss: 1.2098 - val_accuracy: 0.7240\n",
            "Epoch 2/6\n",
            "938/938 [==============================] - 142s 152ms/step - loss: 0.8231 - accuracy: 0.8588 - val_loss: 0.9427 - val_accuracy: 0.8506\n",
            "Epoch 3/6\n",
            "938/938 [==============================] - 146s 155ms/step - loss: 0.7091 - accuracy: 0.8965 - val_loss: 0.8577 - val_accuracy: 0.8602\n",
            "Epoch 4/6\n",
            "938/938 [==============================] - 139s 148ms/step - loss: 0.6483 - accuracy: 0.9160 - val_loss: 0.8757 - val_accuracy: 0.8646\n",
            "Epoch 5/6\n",
            "938/938 [==============================] - 141s 150ms/step - loss: 0.6076 - accuracy: 0.9297 - val_loss: 0.6792 - val_accuracy: 0.9230\n",
            "Epoch 6/6\n",
            "938/938 [==============================] - 138s 148ms/step - loss: 0.5863 - accuracy: 0.9365 - val_loss: 0.6957 - val_accuracy: 0.9190\n",
            "313/313 [==============================] - 18s 58ms/step - loss: 0.8918 - accuracy: 0.8815\n",
            "Test Accuracy: 88.15%\n",
            "Test Loss: 0.8918\n"
          ]
        }
      ],
      "source": [
        "# Compile the model with an optimizer and loss function\n",
        "model_wa_cmos.compile(\n",
        "    optimizer='adam',                      # Adam optimizer is often effective for training binarized networks\n",
        "    loss=\"sparse_categorical_crossentropy\",# Cross-entropy loss for classification\n",
        "    metrics=[\"accuracy\"]                   # Accuracy as the evaluation metric\n",
        ")\n",
        "\n",
        "# Train the model where QAT takes place as the model learns to optimize quantized weights and activations.\n",
        "history_wa_cmos = model_wa_cmos.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=6,                           # Number of training epochs\n",
        "    batch_size=64,                      # Batch size for training\n",
        "    validation_data=(test_images, test_labels), # Evaluate on test set after each epoch\n",
        "    shuffle=False                        # Shuffle the training data for each epoch\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "test_loss, test_accuracy = model_wa_cmos.evaluate(test_images, test_labels)\n",
        "\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}