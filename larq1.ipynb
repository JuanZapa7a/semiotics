{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMYF1togkqwLIdZ1LgC7r2q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuanZapa7a/semiotics/blob/main/larq1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pasos para Implementar y Comparar VGG8 Normal vs. Hardware-Aware en Larq\n",
        "\n",
        "**Larq** es una librería diseñada para construir y entrenar redes neuronales binarizadas (BNNs) utilizando TensorFlow y Keras. Si estás interesado en realizar un entrenamiento consciente del hardware (considerando ruido, cuantización, etc.) para **VGG8** usando **Larq**, puedes lograrlo aprovechando las funcionalidades específicas de **Larq** para la binarización y entrenamiento de modelos compactos."
      ],
      "metadata": {
        "id": "tdims5EPypq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow==2.14.0 larq==0.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry2lhhxw9YkP",
        "outputId": "6587bd46-b00f-47b3-a037-fa29dbb32d99"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.14.0 in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Requirement already satisfied: larq==0.13.0 in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.14.0) (2.14.0)\n",
            "Requirement already satisfied: terminaltables>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from larq==0.13.0) (3.1.10)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.14.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "\n",
        "print(tf.__version__)\n",
        "print(lq.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9jzKOor-CwF",
        "outputId": "70ef0b34-5cee-430e-dc91-cc829f3756c2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n",
            "0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **2. Definición del Modelo VGG8 Normal**\n",
        "Primero, definimos la arquitectura estándar de **VGG8** en Larq sin binarización:"
      ],
      "metadata": {
        "id": "3L8Uy15fy1g_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Arquitectura de VGG8 estándar en Larq (sin binarización)\n",
        "def build_vgg8(input_shape=(32, 32, 3), num_classes=10):\n",
        "    model = models.Sequential([\n",
        "        layers.Input(input_shape),\n",
        "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(256, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_vgg8 = build_vgg8()"
      ],
      "metadata": {
        "id": "W8UPf3-V_e_1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. Definición del Modelo Hardware-Aware VGG8**\n",
        "En este modelo, implementamos binarización de pesos y activaciones utilizando **Larq** para simular hardware de baja precisión."
      ],
      "metadata": {
        "id": "3xwLie2c_xiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Arquitectura de VGG8 con binarización (Hardware-Aware)\n",
        "def build_hw_aware_vgg8(input_shape=(32, 32, 3), num_classes=10):\n",
        "    kwargs = dict(input_quantizer=\"ste_sign\", kernel_quantizer=\"ste_sign\", kernel_constraint=\"weight_clip\")\n",
        "    model = models.Sequential([\n",
        "        lq.layers.QuantConv2D(64, (3, 3), padding='same', activation='relu', **kwargs),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        lq.layers.QuantConv2D(128, (3, 3), padding='same', activation='relu', **kwargs),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        lq.layers.QuantConv2D(256, (3, 3), padding='same', activation='relu', **kwargs),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        lq.layers.QuantDense(256, activation='relu', **kwargs),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model_hw_aware_vgg8 = build_hw_aware_vgg8()"
      ],
      "metadata": {
        "id": "nxf3mlf3AGaU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. Compilación de los Modelos**\n",
        "Compilamos ambos modelos utilizando el optimizador Adam y la pérdida de entropía cruzada."
      ],
      "metadata": {
        "id": "RandbkqWANjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_vgg8.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model_hw_aware_vgg8.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cIOES_gbARO_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **5. Preparación del Dataset CIFAR-10**\n",
        "Utilizaremos **CIFAR-10** para entrenar ambos modelos. Realizamos una normalización básica en las imágenes."
      ],
      "metadata": {
        "id": "Dg2NW1YPAkZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Carga de datos y preprocesamiento\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "vIBoiVk2AnRa",
        "outputId": "962dc86b-96e9-4d81-bbbe-0f9cbcda1323",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 18s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **6. Entrenamiento de los Modelos**\n",
        "Entrenamos ambos modelos con los mismos datos y evaluamos su rendimiento."
      ],
      "metadata": {
        "id": "Bp3gZ_l4Axk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "batch_size = 64\n",
        "\n",
        "# Entrenamiento del modelo normal\n",
        "history_vgg8 = model_vgg8.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))\n",
        "\n",
        "# Entrenamiento del modelo Hardware-Aware\n",
        "history_hw_vgg8 = model_hw_aware_vgg8.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "xlQU6VWIA1p7",
        "outputId": "ca6629a3-fd49-4dac-fbd7-deb54b73ebf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "270/782 [=========>....................] - ETA: 3:06 - loss: 1.6684 - accuracy: 0.3914"
          ]
        }
      ]
    }
  ]
}